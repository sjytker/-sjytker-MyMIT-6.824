# LAB1

### 简介

- 参考 map-reduce 论文，实现一个简易的分布式 map-reduce 
- 没有容错机制，如果发生网络问题会产生错误的计算结果

（代码 600 行左右）



### 算法流程

![image-20210103214329668](D:\distributed_system\6.824\assets\设计思路\image-20210103214329668.png)

1. 用哈希函数把输入文件划分为 M 份，通常每份 16 ~ 64 MB。即 M 个 map task，map 把输入的 input pair 转化为 intermediate key/value pairs
2. 把中间值的输出划分为 R 分，即 R 个 reduce task，reduce 把 intermediate key/value pairs 转化为最终结果
3. master 负责任务调度，把所有任务放在 mater.freeTaskQueue 里，逐个分发给空闲的 worker
4. master.phase 设计 5 种状态：
   - "MAP" ：正在分配 map 任务
   - "MAP_BARRIER" ：已分配完所有 map 任务给 worker，设置栅栏等待完成
   - "REDUCE" ：正在分配 reduce 任务
   - "REDUCE_BARRIER" ：已分配所有 reduce 任务给 worker，设置栅栏等待完成
   - "FIN"：所有任务已完成
5. Task 设置三种状态：
   - IDLE
   - IN_PROGRESS
   - COMPLETE
6. master 用一条独立的 go 线程调度 task，处理不同状态的转换、队列维护、master.phase 的转换
7. worker 不断请求 master 分配任务，当 master reply 无任务分配时，sleep 一段时间，否则执行对应任务。如果 reply 所有任务已完成，则 worker 进程退出。
8. worker 完成当前任务后，也要汇报给 master，让 master 在调度线程中调整这个任务的状态
9. 由于 map task 哈希保存的 bucket 各种 key 是乱的，因此 reduce 前要先对 key 作排序







# LAB2

### 简介

- 参考 Raft 论文，实现 leader election, log replication, persist 三个功能

（代码 3500 行左右）



## LAB2A - Leader Election

参考 Raft 论文 figure2 实现选主

- 所有 server 有三种状态
  - FOLLOWER
  - CANDIDATE
  - LEADER
- 每个 server 都设定一个范围内的随机 election timeout，超出这个时间后，server 就从 FOLLOWER 转变为 CANDIDATE，此时 server.current += 1，并且 voteFor 自己，向所有其他 server 发送 `RequestVote` 请求，如果收到的 grantVote 超过半数（包括自己），则角色转为 LEADER
- 收到 `RequestVote` 请求的 server，根据以下规则判断是否 grantVote：
  - 如果 args.term == rf.currentTerm，并且该 server 曾投给这个 candidate，grantVote。这种情况出现在网络延迟 candidate 重复发送，导致该 server 收到了两次
  - 如果 args.term > rf.currentTerm，那么该 server 转变为 FOLLOWER，并且 rf.voteFor 清空，即没有投给任何人，然后继续根据 log 的新旧判断是否 grantVote
  - 如果 rf.voteFor == -1，并且 candidate 的 log 并当前这个 server 的 log 更新（该 server 的lastLogTerm 更小，或相等但该 server 的 lastLogIndex 更小），grantVote

- candidate 向其他 server sendRequest 时，用 waitGroup 作同步。在 for 循环中，每个循环都新建一个 go routine 发送 RPC 至对应 server，全部发送完毕后，调用 wg.Wait() 等待。无论 RPC 发送成功还是失败都调用一次 wg.Done() 计数
- 用 select 对 sendRequest 主线程作阻塞，当 waitGroup 计数完毕后，往 resCh <- true，以让 select 接触阻塞。
- 在 candidate sendRequest 时，可能受到 term 更大的 reply，这种情况出现在 candidate 下线了，上线后还没来得及受到 AE 刷新，就开始了 election，然后发现已经有其他 leader 了。收到这种 reply 时就应该把 candidate 的身份马上转变为 FOLLOWER，并且更新自己的 rf.term
- candidate 成功当选后，更新所有 nextIndex[] 为自己当前 log 的长度，matchIndex[] 为全 0。并且马上置零 AETimer，使其立刻 AE







## LAB2B - Log Replication

参考 Raft 论文 figure2 实现日志同步

- leader 每隔一段固定时间就会向其他 server 发送 append_entries（AE），已保持心跳联系以及同步日志

- leader 对每个 server 都发送不同的匹配参数，并且每个 server 的网络和响应时间都不一样，因此和 leader election 处理类似，对每个 server 的发送都用一个 go routine 处理。参数根据 leader 维护的 nextIndex[] 数组取出：prevLogIndex, prevLogTerm, entries[]

- 收到 AE 的 server，如果 args.term 比自己的小，说明自己的 log 更新，reply 返回 false 以及自己的 term，让发 AE 的 LEADER 转变为 FOLLOWER 并更新 currentTerm

- 如果不 reply false，那么重置该 server 的 electionTimer，不让它超时成为 candidate

- 更新自己的 currentTerm，并检查 AE 发来的 log 和自己的 log 是否能对接上，这通过检查自己的 lastLogIndex 和 lastLogTerm 与发来的 AE 是否能对应上，如果恰好对接上，那么更新自己的 log，否则，按以下规则发回数据让 leader 调整 log：

  - 最简单的办法：leader 每次回退一格 log。如果 server 落后太多，leader 就要重发很多次，比较慢。但 Raft 论文作者提到，其实这么做也是可以接受的，因为在 99% 的情况下 leader 和 follower 的日志都不会差太远，优化回退速度的意义有限。

  - 加速回退办法：server 发现 log 不匹配时，server 计算出以下几个变量，向 leader 发回以加速回退，包括：

    ```
        XTerm:  term in the conflicting entry (if any)
        XIndex: index of first entry with that term (if any)
        XLen:   log length
    ```

- leader 根据以下规则加速回退：

  - ```tex
      Case 1 (leader doesn't have XTerm):
        nextIndex = XIndex
      Case 2 (leader has XTerm):
        nextIndex = leader's last entry for XTerm
      Case 3 (follower's log is too short):
        nextIndex = XLen
    ```

  - 先看 XLen 是否存在，是则用 XLen 更新

  - 否则检查 XTerm是否存在，存在则扫一遍 leader's log，找出最右侧 term == Xterm 的 log

  - 如果 XTerm 不存在，说明 leader 在这个 term 期间是 offline 的，因此 leader 对这个 server 的 nextIndex[] 数组应该更新到此位置。下一个 AE 应对比 XIndex - 1 位置是否匹配得上。并且，这个 server 虽然此处有 log，但它实际上这部分 log 没有取得 majority，更没有被 apply，因为如果这部分 log 已经被 apply，那么当前 server 的 log 就不是最新的，它就不可能当选。

    

#### 乱序到达

- 如果收到乱序的 AE，必须丢弃，不能把它覆盖到当前的 log。因为 Raft 论文没有提到这个问题，一开始我没有处理，导致有些 test 总是跑不对。



### Commit

#### leader

- 对于 leader，每一个 server AE 成功时，都检查是否需要推进 commitIndex。
- 推进规则：半数以上的 servers matchIndex 已经到达此处

#### Folloer

- 对于 follower，如果 AE 匹配成功，并且 leader 的 args.leaderCommit > rf.commitIndex，那么推进这个 follower 的 commitIndex，但不能超过 lastLogIndex。即：

  ```tex
  	rf.commitIndex = min(args.LeaderCommit, lastLogIndex)
  ```



### Apply 

- 每个 server 都开一条独立的 routine 来 apply log，每隔 100ms 查询一次，是否有新的 log 需要 apply
- 如果当前 rf.lastApplied 落后于 commitIndex，那么对 log 逐个 apply，并推进 rf.lastApplied
- 做法是，构建一个 ApplyMsg 结构，把 valid, command, commandIndex 放进去，然后推到 “0 容量的 applyCh”
- 上层的 kv-server 通过这个 applyCh 收到信息，就知道现在需要 apply 新的数据，更新 kv 数据库





## LAB2C

#### 为什么要 persist:	

​	当 raft server reboot 时，它的状态信息会清空，此时如果接受新的 AE，就会重新 apply所有 log，这是没有必要的。为了使它能从上一个 checkpoint 继续运行，我们需要在适当的时候保存状态

- 以下状态改变时，就需要保存到本地：
  - commitIndex
  - lastApplied
  - NextIndex[]
  - matchIndex[]
- 用 Encoder 把这些数据逐个 encode，然后保存就好了
- 要注意的是：用 Decoder decode 时，要按 encode 的顺序，否则会报错。踩过坑







# LAB3

### 简介

- 基于底层的 Raft 一致性算法，实现上层的 key-value 数据库
- 实现 log compaction



## LAB3A - k/v service

- client 进程用一条独立的线程来 FindLeader，设置一个 FindLeaderTimeout，我这里取 300ms
- FindLeader 函数对所有 server 发送 RPC，找到是 leader 的那一个，保存在 client 对象属性中
- 客户端收到 get 或 put 消息，通过 RPC 发送到当前的 ck.leader
  - 如果收到 RPC 的 server reply 已不是 leader，那么 client 清零 finderLeaderTimer，马上开始寻找新的 leader，并休眠一段时间等待结果
  - 如果收到 RPC 的 server 是 leader，那么进行把 get/put 命令添加到 Raft Log 中，等待同步

- Raft 对命令同步完成后，便开始 apply
- k/v server 收到底层 raft apply 的消息是随机的，并不一定按 client 提交命令的顺序 apply。因此需要用一个 map[id] channel 结构来保存所有需要等待 apply 的请求，线程在 select 代码块等待 Raft apply 完成。每次 apply 完毕就删除这个 channel。这个 id 下面会进一步讨论。



#### 重复到达

- server 必须要有去重机制，也就是如果同一个 append 命令因为网络故障发送了两次，那么我们显然不能执行两次。
- 这里提交 log 时要设置两个随机数
  - op.msgId：用于记录消息的唯一性
  - op.reqId：用于记录请求的唯一性。注意，一个消息可能有多个请求
- 为了不重复 apply，我们再 applyCh 收到 msg 时，就检查 msgId 是否已经被 applied，这可以通过用哈希表保存 {clientId，msgId} 达到。当收到这个 clientId 的 apply 消息时，如果它刚被 applied 了，那么现在这个 server 就不需要更新自己的 k/v 数据库了
- 那为什么要用 reqId 呢？
  - 如果对 client 的每个 get/put 命令，都用唯一的 msgId 作为 key，那么当 client 超时收不到 server 的相应并重发时，底层 Raft 可能就复制了两条相同的消息，虽然在去重机制下只有一条作用于 k/v 数据库，但 map[id] channel 却只有一个 channel，如果两条线程在 select 都阻塞于这个 channel，那么只有一条线程会获取消息，另一条线程将永远死锁







## LAB3B - log compaction

​	当 log 越来越长时，占用的内存空间也越来越多，此时前面一部分已同步完毕的 log 可能不再需要使用了，可以通过 snapshot 文件本地化到磁盘

- 每次 k/v server apply 新的操作后，我们都检查是否需要更新 snapshot。可以自由设定 log 的长度大于特定数值时，保存 snapshot
- snapshot 包括：
  - kv.data：map 形式的 k-v pair
  - kv.lastApplied：map 形式保存 clientId 上一个 apply 的操作
- 需要注意的是，保存 k/v server snapshot 的同时，还要保存 Raft 的 data，即调用 LAB2C 所写的 persist 等函数， 包括
  - 前面 persist 的所有变量
  - lastSnapshotTerm
  - lastSnapshotIndex





# LAB4

### 简介

- lab4 要求数据库分库，以提高访问速度，因为如果只有一个 cluster，那么 client 请求越来越多时，leader 的队伍会非常长，client 的请求时延就会很高
- 解决办法是，把不同范围的 key 哈希到不同的 cluster 中，每个 cluster 都是一个基于 raft 一致性算法的集群，拥有 3 或 5 个 server，各自有一个 leader。这样就降低了请求延迟
- 分为 ShardMaster 和 ShardKV 两个模块，ShardMaster 负责解决加入和移除 cluster 时 Shard (子库) 的重新分配；ShardKV 解决 k-v 数据库的分库请求



### ShardMaster

#### 注意点

- master 和 group 都是有 3、5 个 server 的集群。其中 master 像 lab3 实现 k-v service 一样实现 client, server。log 有 join, leave, move, query 四种不同操作的命令，分别是加入 cluster，移除 []gids 的 cluster，手动更改 shard 的 gid，查询某个 index 的 config
- ShardMaster 不需 persist log，因为 shardMaster 是对 cluster 的历史操作，即使 offline 了，现有的 cluster configuration 依然是没有改变的。
- 需要注意 golang RPC 传输 interface 参数时，需要用 gob.register 注册这个 interface 可能出现的类型。可以把这些 register 放在包初始化函数 init() 中

#### 关键设计

- 重点关注 join 和 leave 两个操作，其中 join 使当前 config group 长度变大，avg = NShard / len(config.groups) 小于等于 lastConfig 。而 leave 与之相反
- 由于 lab4 要求增加或删除 cluster 时，Shards 变动尽可能小，因此不能暴力把 lastConfig 的 Shards 清空，然后重新分配，因为这样使得新旧 config 重合部分的 Shards 也重分配了，而它们实际上不需要被重分配。
- 新旧 config 可以如下图示：  ###....x1....||.....x2....###......x3.....||     其中 x2 是重合部分。不妨设 x1, x2 是新 config， x2, x3 是旧 config
- 先求出 avg = NShards / len(config.Group),   left = NShard % len(config.Group)
  1. 当 curLen < lastLen，也就是 leave 时，我们从 x3 分部分 shards 到 x1, x2 中，其中 x2 可能不需要被增加。遍历所有 config.Groups。 r = avg - lastCnt[gid]  。FIRST,  move x3 to x2，注意此时要检查两次，如果 left > 0，分配多余的 1 之前和之后 r 是否为 0，如果是 0 就不用调整了。 SECOND，move x3 to x1。
  2. 当 curLen >= lastLen，也就是 join 时，每个新 Group 的 Shard <= 每个旧 Group 的 Shard。可以用和上一种情况同样的思路做，但这里我采取了另一种不同的思路：先把 x2 多余部分以及 x3 的 config.Shard[i] = 0，清零后再把它们统一分配到 x1 中。
- ShardMaster 有三种状态，STABLE, TRANSITION, FREEZE。其中只有 STABLE 状态可以执行 join, leave, move。 TRANSITION 为 RAFT 正复制新的 configuration，FREEZE 为同步完毕，等待一段时间让 ShardKV 也进行数据迁移。



### ShardKV

- 用一个 go routine 不断询问 ShardMaster 最新的 configuration
- Get 和 PutAppend 时，区分 ErrWrongLeader 和 ErrWrongGroup 两种错误，前者在同 group 换 server 发送，后者换 group 发送
- 与非分库的 k-v service 实现相比，非分库只用一个 map[string]string 结果存储数据，分库时需要每个 Shard 作为 key 保存一个 map，也就是 map[int]map[string]string
- shardMaster 更新 configuration 后，ShardKV 需要立马跟进吗？好像不影响对 client 提供服务，晚一点让 findConfig() 跟进也没关系。但可能会产生并发问题，如果 server 收到了 get 请求，此时又刚好发生 data migration，把这个 get 对应的 shard 删除了，那么最后会 get 到错误的空字符串。因此 migration 一但开始了就不能接受其他 get, put 请求。

  

#### 关键设计

- ShardKV serivce 的关键问题是，在 ShardMaster 改变 configuration 时，如何把对应子库 shard 的 k-v 数据迁移到另一个 gid？      
- 我的解决办法是，在 ShardKV server 收到 get, put 请求时，sever 发给 ShardMaster 判断当前 shard 是否在我这个 gid，如果已经不在了，那么让 ShardKV client 遍历所有 gid，找到所在的一个。然后把 oldGid 这个 Shard 对应的 data 发往 newGid  
- 新问题：如果按上述设计，只能解决哈希到 oldGid 时的数据迁移问题，如果一开始就哈希到 newGid 呢
- 解决办法：
  1. 先比较 lastConfig 和 curConfig 的 group 数量是否不同，如果有所改变，client 先请求 lastConfig，如果这个 key 已经执行过 migration，那么请求 curConfig
  2. Shard server 周期性 findConfig 时，如果当前 config 长度和上一个不同，那么发生了迁移。当前 gid server 的 shard 如果迁到了其他 gid，那么主动调用 RPC 把它迁过去。

- 拉取 config 时，只能让 leader 拉取，follower 不能拉取。因为我的数据 migration 逻辑是用 leader 判断新 config group len 是否变化。如果 follower 拉取，此时 cluster 又不存在 leader 的话，新 leader 上任时拉取 config 会认为无变化。而如果无 leader 时 ShardMaster 执行了 join / leave 就报错了。

