





# LAB2





# LAB3





# LAB4

#### 简介

- lab4 要求数据库分库，以提高访问速度，因为如果只有一个 cluster，那么 client 请求越来越多时，leader 的队伍会非常长，client 的请求时延就会很高
- 解决办法是，把不同范围的 key 哈希到不同的 cluster 中，每个 cluster 都是一个基于 raft 一致性算法的集群，拥有 3 或 5 个 server，各自有一个 leader。这样就降低了请求延迟
- 分为 ShardMaster 和 ShardKV 两个模块，ShardMaster 负责解决加入和移除 cluster 时 Shard (子库) 的重新分配；ShardKV 解决 k-v 数据库的分库请求



### ShardMaster

#### 注意点

- master 和 group 都是有 3、5 个 server 的集群。其中 master 像 lab3 实现 k-v service 一样实现 client, server。log 有 join, leave, move, query 四种不同操作的命令，分别是加入 cluster，移除 []gids 的 cluster，手动更改 shard 的 gid，查询某个 index 的 config
- ShardMaster 不需 persist log，因为 shardMaster 是对 cluster 的历史操作，即使 offline 了，现有的 cluster configuration 依然是没有改变的。
- 需要注意 golang RPC 传输 interface 参数时，需要用 gob.register 注册这个 interface 可能出现的类型。可以把这些 register 放在包初始化函数 init() 中

#### 关键设计

- 重点关注 join 和 leave 两个操作，其中 join 使当前 config group 长度变大，avg = NShard / len(config.groups) 小于等于 lastConfig 。而 leave 与之相反
- 由于 lab4 要求增加或删除 cluster 时，Shards 变动尽可能小，因此不能暴力把 lastConfig 的 Shards 清空，然后重新分配，因为这样使得新旧 config 重合部分的 Shards 也重分配了，而它们实际上不需要被重分配。
- 新旧 config 可以如下图示：  ###....x1....||.....x2....###......x3.....||     其中 x2 是重合部分。不妨设 x1, x2 是新 config， x2, x3 是旧 config
- 先求出 avg = NShards / len(config.Group),   left = NShard % len(config.Group)
  1. 当 curLen < lastLen，也就是 leave 时，我们从 x3 分部分 shards 到 x1, x2 中，其中 x2 可能不需要被增加。遍历所有 config.Groups。 r = avg - lastCnt[gid]  。FIRST,  move x3 to x2，注意此时要检查两次，如果 left > 0，分配多余的 1 之前和之后 r 是否为 0，如果是 0 就不用调整了。 SECOND，move x3 to x1。
  2. 当 curLen >= lastLen，也就是 join 时，每个新 Group 的 Shard <= 每个旧 Group 的 Shard。可以用和上一种情况同样的思路做，但这里我采取了另一种不同的思路：先把 x2 多余部分以及 x3 的 config.Shard[i] = 0，清零后再把它们统一分配到 x1 中。



### ShardKV



