

## lab2 有小概率 failTest（困难)

- 在写完 lab2 后，由于存在很多随机的 timeout，所以一次测试成功 pass 不能代表永远能 pass。用一个脚本自动跑 500 次 lab2ABC test（每次有 20+ 个 test 函数)

- 经过一系列 debug，还是有小概率 failTest。500 次 fail 10 次，错误主要 fail to reach agreement ，原因是：没leader；有 leader，但 commit 的不够

- 查了几天日志，反复看了 paper 和参考别人的代码实现。我百思不得其解，明明逻辑都是对的，为什么会有 2% 概率 fail test？

- 暂时找不到突破口，我决定把日志打得更详细一些，每一个判定流程，都打个日志看看当前状态如何。

- 用 subline 打开几万行的日志，定位的关键的几千行之间反复看，突然注意到：有时候选不出 leader，不是由于 election 或 replication 的逻辑错误，而是网络发送的包延迟到达了，超过了程序设定的 RPCTimeout 参数，自动结束了 election。因此 candidate 没有收到 follower 的投票，导致一直选不出 leader。

- fail to reach agreement 错误，也是同样情况，AE match fail 几次，并且网络发包屡屡延时到达，导致出现不该出现的 election timeout，然后出现复杂的奇怪的问题。

- 值得注意的是，这个 test 的 golang 代码并非真的通过网络发送 RPC，而是在本地模拟。所以它不是消耗网络资源的，而是消耗 CPU

- 于是我把 RPCTimeout, beatPeriod 等参数都调了一下，虽然不同参数下 fail 概率不同，但都会 fail，始终没找到怎么解决。

  

- 最终发现了两个问题，都是 Raft 论文中没有提到的：

  1. 参考他人代码发现：选主逻辑没有完全写对：如果 args.term == rf.currentTerm，且 voteFor != -1 ，那么这个 follower 曾经投给了其他人，他就不再投票了，即使 candidate 的 log 非常新。这时候根据 voteFor 是否等于 candidateId 返回 true or false。

  2. 看课程 student guide 发现：乱序到达的 AE，我没有特殊处理。有时候 leader 发的旧 AE 堵塞在网络中，但是有新 leader 的新log 已到达，那么如果旧 AE 覆盖了新 AE，那么 leader 已经 applied 到后面了，并且认为 follower 也 applied 到了后面，但是事实上这个 server 并没有 applied 到后面。

     这在测试中会报 fail to reach agreement 错误。

- 显然，这两种情况没有论文可依，如果光凭自己 YY ，很难想到代码没覆盖到什么情况。毕竟 Raft 论文是 Standford PHD 的大作，而我在分布式领域经验不多，要是纯凭一己之力解决所有这些问题实在太难了。

  





## Client 请求死锁

如果对整个 apply() 函数加锁，可能会死锁，原因如下：

- for isLeader{} 的循环中，每次 apply timeout 都要重新判断当前是否 leader，而调用 rf.getState() 也要加锁
- 但注意，如果此时线程调度到 rf leader，并且 msg 已经放入了 apply channel，那么这个 rf leader 将带 mutex 阻塞在 channel，kvserver 想通过 rf.getState() 判断是否还是 leader，将永远获取不到锁。

#### 解决方法：

* 不要拿着 mutex 等 channel
* 不要拿着 mutex 等 channel
* 不要拿着 mutex 等 channel
* 把临界变量加锁取出来，解锁。再 block in channel





## kvserver 提交 cmd 的问题

#### **问题**： 

​	起初，我在 kvserver putAppend 或 get 后，阻塞在 rf.applyChan 监听提交，但是这有一个问题。如果在 applyTimeout 内，deposed leader 被 AE 刷新成 follower，然后在 applyChan apply 了新的 log，那么这个 kvserver 从 applyChan 读取到的 log 将和前面 start() 的 log 不符。

#### 解决：

1. 给 log 加入 unique requestID，每次从 channel 中收到消息时，检查这个消息的 requestID 是否和自己发出去的一致。

2.  不可以让 KVServer 阻塞在 apply chan，因为选出新 leader 时，会重新提交以前已经提交过的 log。如果阻塞在 apply chan，就大概率会收到和当前 RequestID 不一致的 log，然后返回 ErrNoLeader 错误。

   正确的做法：

   - 创建一个独立的 waitApplyCh 函数来阻塞监听 ApplyChan
   - 创建一个 NotifyMsgChan 来监听当前 RequestID 是否被被 ApplyChan 提交，如果是则往 NotifyMsgChan  推消息，否则不理。
   - 设置一个 Timeout，超出此事件还没受到 NotifyMsgChan 则中断等待。此时可能是这个 server 处于 minority partition 中，导致一直无法将命令 commit。应在 client 程序重新寻找 leader。















---

> #### 其他小问题





## 日志太大，很难定位错误

- 在写第二个任务，KVservice 的时候，日志已经涨到 50-100 MB。而且 KVservice 和 Raft 存在不小的耦合度，导致每次测试出错时都很难定位，到底出了什么问题。每次找一个小错误，都得花上半天甚至超过一天。

  

#### 解决：

- 可以逐个函数或模块看，是否出现了行为异常
- 可以对总体流程作二分，先查中间步骤是否出错，如果没有则查后 1 / 2，如果有则查前 1 / 2……







## json.NewEncoder 无法写入文件

**解决**：

​	struct 可导出性的问题，必须 uppercase 开头的变量才是可导出的，才能被写入 json 文件



## rpc 调用找不到 master 的函数

**问题**：

​	我在 master 写了 2 个 rpc 调用函数，其中一个能正常调用。另一个报错找不到该方法。调用方式完全一致，并且 master 也确定有 worker 调用的同名函数。

​	（搞了半天才找到问题）

**解决**：

​	还是 Golang exported 类型的问题。无论是 type，还是参数，都只有 uppercase 开头才是 exported，否则 unexported。

​	在 unexported 的情况下，文件不能写入，rpc 也无法调用。



## Mutex 的问题

​	Java 的 lock, synchronized 是可重入锁，而 golang 的 mutex 是不可重入的。C ++ 也不可重入



## 共享变量问题

​	由于每个 Raft 对象既发送，又接收，它的对象变量是共享的，所有访问到共享变量的函数都应该加锁。否则会出现并发问题。

​	但是锁粒度不宜太大，也就是说，不需要整个函数都加锁，而是读取和修改共享变量时加锁，完毕后释放。



## Election 忙等

​	一开始我用 waitGroup（效果与 Java CountDownLatch 相同）等待所有 server 返回 RequestVote 结果。忽略了如果此时有 server down 无法选出 leader 的问题。

​	加上 time.Timer 来计时，timeout 则退出。设置常量 RPCTimeout











